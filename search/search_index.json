{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Larry's Pellets Dosing Site (LPDS) documentation \u00b6 Reference : BiosanaID LPSD is a modern, fast (high-performance), web interface to administer testosterone dosis to patientes via pellets. The key features are: Fast to diagnose doses : Increase the speed to calculate and print reports if needed. * Fewer bugs : Reduce about 40% of human (doctors, practitioners, nurses) induced errors. * Short : Minimize code duplication. Multiple features from each parameter declaration. Fewer bugs. Intuitive : Great look and feel, ease the navigation, supports global search and filtering capabilites. Completion everywhere. Easy : Designed to be easy to use and learn. Less time reading docs. Adaptable to light conditions (light and dark modes) Robust : Get production-ready code and available with fast deployments cycles upon new business needs, including automatic interactive documentation. Fast performance : Very high performance, FastAPI(thanks FastAPI and Starlette and Pydantic). Standards-based : Based on (and fully compatible with) the open standards for APIs: OpenAPI (previously known as Swagger) and JSON Schema . * estimation based on tests on an internal development team, building production applications.","title":"Home"},{"location":"#welcome-to-larrys-pellets-dosing-site-lpds-documentation","text":"Reference : BiosanaID LPSD is a modern, fast (high-performance), web interface to administer testosterone dosis to patientes via pellets. The key features are: Fast to diagnose doses : Increase the speed to calculate and print reports if needed. * Fewer bugs : Reduce about 40% of human (doctors, practitioners, nurses) induced errors. * Short : Minimize code duplication. Multiple features from each parameter declaration. Fewer bugs. Intuitive : Great look and feel, ease the navigation, supports global search and filtering capabilites. Completion everywhere. Easy : Designed to be easy to use and learn. Less time reading docs. Adaptable to light conditions (light and dark modes) Robust : Get production-ready code and available with fast deployments cycles upon new business needs, including automatic interactive documentation. Fast performance : Very high performance, FastAPI(thanks FastAPI and Starlette and Pydantic). Standards-based : Based on (and fully compatible with) the open standards for APIs: OpenAPI (previously known as Swagger) and JSON Schema . * estimation based on tests on an internal development team, building production applications.","title":"Welcome to Larry's Pellets Dosing Site (LPDS) documentation"},{"location":"pages/","text":"Features \u00b6 User Registration Authentication using JWT and OAuth \"password flow\" using PyJWT JSON-Web-Token based authentication Writing & modifying patient and doctors data on the database. Backend API endpoints for general and to support CRUD operations Manage patients and users. Calculate pellets dose based on scientific data and algorithm (business logic) Security","title":"Getting Started"},{"location":"pages/#features","text":"User Registration Authentication using JWT and OAuth \"password flow\" using PyJWT JSON-Web-Token based authentication Writing & modifying patient and doctors data on the database. Backend API endpoints for general and to support CRUD operations Manage patients and users. Calculate pellets dose based on scientific data and algorithm (business logic) Security","title":"Features"},{"location":"pages/billing/","text":"This software application will cost 15000 dollars, including the full development lifecycle iterations up un until the release. If further modifications/updates/removals are requested there will be an additional charge depending on the complexity of the change.","title":"Agreement for billing and maintenance costs"},{"location":"pages/browser/","text":"Browser support \u00b6 Material for MkDocs goes at great lengths to support the largest possible range of browsers while retaining the simplemost possibilities for customization via modern CSS features like custom properties and mask images . Supported browsers \u00b6 The following table lists all browsers for which Material for MkDocs offers full support, so it can be assumed that all features work without degradation. If you find a feature not to be working in a browser in the supported version range, please open an issue : Browser support matrix sourced from caniuse.com . 1 Note that the usage data is based on global browser market share, so it could in fact be entirely different for your target demographic. It's a good idea to check the distribution of browser types and versions among your users. Other browsers \u00b6 Albeit your site might not look as perfect as when viewed with a modern browser, the following older browser versions might work with some additional effort: :fontawesome-brands-firefox: Firefox 31-52 \u2013 icons will render as little boxes due to missing support for mask images . While this cannot be polyfilled, it might be mitigated by hiding the icons altogether. :fontawesome-brands-edge: Edge 16-18 \u2013 the spacing of some elements might be a little off due to missing support for the :is pseudo selector , which can be mitigated with some additional effort. :fontawesome-brands-internet-explorer: Internet Explorer - no support, mainly due to missing support for custom properties . The last version of Material for MkDocs to support Internet Explorer is :octicons-tag-24: 4.6.3 . The data was collected from caniuse.com in January 2022, and is primarily based on browser support for custom properties , mask images and the :is pseudo selector which are not entirely polyfillable. Browsers with a cumulated market share of less than 1% were not considered, but might still be fully or partially supported. \u21a9","title":"Browser support"},{"location":"pages/browser/#browser-support","text":"Material for MkDocs goes at great lengths to support the largest possible range of browsers while retaining the simplemost possibilities for customization via modern CSS features like custom properties and mask images .","title":"Browser support"},{"location":"pages/browser/#supported-browsers","text":"The following table lists all browsers for which Material for MkDocs offers full support, so it can be assumed that all features work without degradation. If you find a feature not to be working in a browser in the supported version range, please open an issue : Browser support matrix sourced from caniuse.com . 1 Note that the usage data is based on global browser market share, so it could in fact be entirely different for your target demographic. It's a good idea to check the distribution of browser types and versions among your users.","title":"Supported browsers"},{"location":"pages/browser/#other-browsers","text":"Albeit your site might not look as perfect as when viewed with a modern browser, the following older browser versions might work with some additional effort: :fontawesome-brands-firefox: Firefox 31-52 \u2013 icons will render as little boxes due to missing support for mask images . While this cannot be polyfilled, it might be mitigated by hiding the icons altogether. :fontawesome-brands-edge: Edge 16-18 \u2013 the spacing of some elements might be a little off due to missing support for the :is pseudo selector , which can be mitigated with some additional effort. :fontawesome-brands-internet-explorer: Internet Explorer - no support, mainly due to missing support for custom properties . The last version of Material for MkDocs to support Internet Explorer is :octicons-tag-24: 4.6.3 . The data was collected from caniuse.com in January 2022, and is primarily based on browser support for custom properties , mask images and the :is pseudo selector which are not entirely polyfillable. Browsers with a cumulated market share of less than 1% were not considered, but might still be fully or partially supported. \u21a9","title":"Other browsers"},{"location":"pages/cloud/","text":"Dosing site will have two pay-per-use platforms to be hosted Deta for API backend Netlify for ReactJS frontend","title":"Deploying our application to Cloud"},{"location":"pages/db/","text":"Up to this point, we have been working with single container apps. But, we now want to add MySQL to the application stack. The following question often arises - \"Where will MySQL run? Install it in the same container or run it separately?\" In general, each container should do one thing and do it well. A few reasons: There's a good chance you'd have to scale APIs and front-ends differently than databases. Separate containers let you version and update versions in isolation. While you may use a container for the database locally, you may want to use a managed service for the database in production. You don't want to ship your database engine with your app then. Running multiple processes will require a process manager (the container only starts one process), which adds complexity to container startup/shutdown. Container Networking \u00b6 Remember that containers, by default, run in isolation and don't know anything about other processes or containers on the same machine. So, how do we allow one container to talk to another? The answer is networking . Now, you don't have to be a network engineer (hooray!). Simply remember this rule... If two containers are on the same network, they can talk to each other. If they aren't, they can't. Starting MySQL \u00b6 There are two ways to put a container on a network: 1) Assign it at start or 2) connect an existing container. For now, we will create the network first and attach the MySQL container at startup. Create the network. docker network create todo-app Start a MySQL container and attach it to the network. We're also going to define a few environment variables that the database will use to initialize the database (see the \"Environment Variables\" section in the MySQL Docker Hub listing ). docker run -d \\ --network todo-app --network-alias mysql \\ -v todo-mysql-data:/var/lib/mysql \\ -e MYSQL_ROOT_PASSWORD = secret \\ -e MYSQL_DATABASE = todos \\ mysql:5.7 If you are using PowerShell then use this command. docker run -d ` - -network todo-app - -network-alias mysql ` -v todo-mysql-data : / var / lib / mysql ` -e MYSQL_ROOT_PASSWORD = secret ` -e MYSQL_DATABASE = todos ` mysql : 5 . 7 You'll also see we specified the --network-alias flag. We'll come back to that in just a moment. Pro-tip You'll notice we're using a volume named todo-mysql-data here and mounting it at /var/lib/mysql , which is where MySQL stores its data. However, we never ran a docker volume create command. Docker recognizes we want to use a named volume and creates one automatically for us. Troubleshooting If you see a docker: no matching manifest error, it's because you're trying to run the container in a different architecture than amd64, which is the only supported architecture for the mysql image at the moment. To solve this add the flag --platform linux/amd64 in the previous command. So your new command should look like this: docker run -d \\ --network todo-app --network-alias mysql --platform linux/amd64 \\ -v todo-mysql-data:/var/lib/mysql \\ -e MYSQL_ROOT_PASSWORD = secret \\ -e MYSQL_DATABASE = todos \\ mysql:5.7 To confirm we have the database up and running, connect to the database and verify it connects. docker exec -it <mysql-container-id> mysql -p When the password prompt comes up, type in secret . In the MySQL shell, list the databases and verify you see the todos database. mysql> SHOW DATABASES; You should see output that looks like this: +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | | todos | +--------------------+ 5 rows in set (0.00 sec) Hooray! We have our todos database and it's ready for us to use! To exit the sql terminal type exit in the terminal. Connecting to MySQL \u00b6 Now that we know MySQL is up and running, let's use it! But, the question is... how? If we run another container on the same network, how do we find the container (remember each container has its own IP address)? To figure it out, we're going to make use of the nicolaka/netshoot container, which ships with a lot of tools that are useful for troubleshooting or debugging networking issues. Start a new container using the nicolaka/netshoot image. Make sure to connect it to the same network. docker run -it --network todo-app nicolaka/netshoot Inside the container, we're going to use the dig command, which is a useful DNS tool. We're going to look up the IP address for the hostname mysql . dig mysql And you'll get an output like this... ; <<>> DiG 9.14.1 <<>> mysql ;; global options: +cmd ;; Got answer: ;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 32162 ;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0 ;; QUESTION SECTION: ;mysql. IN A ;; ANSWER SECTION: mysql. 600 IN A 172.23.0.2 ;; Query time: 0 msec ;; SERVER: 127.0.0.11#53(127.0.0.11) ;; WHEN: Tue Oct 01 23:47:24 UTC 2019 ;; MSG SIZE rcvd: 44 In the \"ANSWER SECTION\", you will see an A record for mysql that resolves to 172.23.0.2 (your IP address will most likely have a different value). While mysql isn't normally a valid hostname, Docker was able to resolve it to the IP address of the container that had that network alias (remember the --network-alias flag we used earlier?). What this means is... our app only simply needs to connect to a host named mysql and it'll talk to the database! It doesn't get much simpler than that! Running our App with MySQL \u00b6 The todo app supports the setting of a few environment variables to specify MySQL connection settings. They are: MYSQL_HOST - the hostname for the running MySQL server MYSQL_USER - the username to use for the connection MYSQL_PASSWORD - the password to use for the connection MYSQL_DB - the database to use once connected Warning While using env vars to set connection settings is generally ok for development, it is HIGHLY DISCOURAGED when running applications in production. Diogo Monica, the former lead of security at Docker, wrote a fantastic blog post explaining why. A more secure mechanism is to use the secret support provided by your container orchestration framework. In most cases, these secrets are mounted as files in the running container. You'll see many apps (including the MySQL image and the todo app) also support env vars with a _FILE suffix to point to a file containing the variable. As an example, setting the MYSQL_PASSWORD_FILE var will cause the app to use the contents of the referenced file as the connection password. Docker doesn't do anything to support these env vars. Your app will need to know to look for the variable and get the file contents. With all of that explained, let's start our dev-ready container! We'll specify each of the environment variables above, as well as connect the container to our app network. docker run -dp 3000 :3000 \\ -w /app -v \" $( pwd ) :/app\" \\ --network todo-app \\ -e MYSQL_HOST = mysql \\ -e MYSQL_USER = root \\ -e MYSQL_PASSWORD = secret \\ -e MYSQL_DB = todos \\ node:12-alpine \\ sh -c \"yarn install && yarn run dev\" If you updated your docker file in the Bind Mount section of the tutorial use the updated command: docker run -dp 3000 :3000 \\ -w /app -v \" $( pwd ) :/app\" \\ --network todo-app \\ -e MYSQL_HOST = mysql \\ -e MYSQL_USER = root \\ -e MYSQL_PASSWORD = secret \\ -e MYSQL_DB = todos \\ node:12-alpine \\ sh -c \"apk --no-cache --virtual build-dependencies add python2 make g++ && yarn install && yarn run dev\" If you are using PowerShell then use this command. docker run -dp 3000 : 3000 ` -w / app -v \" $( pwd ) :/app\" ` - -network todo-app ` -e MYSQL_HOST = mysql ` -e MYSQL_USER = root ` -e MYSQL_PASSWORD = secret ` -e MYSQL_DB = todos ` node : 12-alpine ` sh -c \"yarn install && yarn run dev\" If we look at the logs for the container ( docker logs <container-id> ), we should see a message indicating it's using the mysql database. # Previous log messages omitted $ nodemon src/index.js [nodemon] 1.19.2 [nodemon] to restart at any time, enter `rs` [nodemon] watching dir(s): *.* [nodemon] starting `node src/index.js` Connected to mysql db at host mysql Listening on port 3000 Open the app in your browser and add a few items to your todo list. Connect to the mysql database and prove that the items are being written to the database. Remember, the password is secret . docker exec -it <mysql-container-id> mysql -p todos And in the mysql shell, run the following: mysql> select * from todo_items; +--------------------------------------+--------------------+-----------+ | id | name | completed | +--------------------------------------+--------------------+-----------+ | c906ff08-60e6-44e6-8f49-ed56a0853e85 | Do amazing things! | 0 | | 2912a79e-8486-4bc3-a4c5-460793a575ab | Be awesome! | 0 | +--------------------------------------+--------------------+-----------+ Obviously, your table will look different because it has your items. But, you should see them stored there! If you take a quick look at the Docker Dashboard, you'll see that we have two app containers running. But, there's no real indication that they are grouped together in a single app. We'll see how to make that better shortly! Recap \u00b6 At this point, we have an application that now stores its data in an external database running in a separate container. We learned a little bit about container networking and saw how service discovery can be performed using DNS. Docker volumes \u00b6 In containerized applications, the data by default is being wiped clean every single time we launch the container. Why is this? Let's dive into how the container is working. The Container's Filesystem \u00b6 When a container runs, it uses the various layers from an image for its filesystem. Each container also gets its own \"scratch space\" to create/update/remove files. Any changes won't be seen in another container, even if they are using the same image. Container Volumes \u00b6 With the previous experiment, we saw that each container starts from the image definition each time it starts. While containers can create, update, and delete files, those changes are lost when the container is removed and all changes are isolated to that container. With volumes, we can change all of this. Volumes provide the ability to connect specific filesystem paths of the container back to the host machine. If a directory in the container is mounted, changes in that directory are also seen on the host machine. If we mount that same directory across container restarts, we'd see the same files. So far, we talked about and used a named volume to persist the data in our database. Named volumes are great if we simply want to store data, as we don't have to worry about where the data is stored. With bind mounts , we control the exact mountpoint on the host. We can use this to persist data, but is often used to provide additional data into containers. When working on an application, we can use a bind mount to mount our source code into the container to let it see code changes, respond, and let us see the changes right away. For Node-based applications, nodemon is a great tool to watch for file changes and then restart the application. There are equivalent tools in most other languages and frameworks.","title":"Persisting our data"},{"location":"pages/db/#container-networking","text":"Remember that containers, by default, run in isolation and don't know anything about other processes or containers on the same machine. So, how do we allow one container to talk to another? The answer is networking . Now, you don't have to be a network engineer (hooray!). Simply remember this rule... If two containers are on the same network, they can talk to each other. If they aren't, they can't.","title":"Container Networking"},{"location":"pages/db/#starting-mysql","text":"There are two ways to put a container on a network: 1) Assign it at start or 2) connect an existing container. For now, we will create the network first and attach the MySQL container at startup. Create the network. docker network create todo-app Start a MySQL container and attach it to the network. We're also going to define a few environment variables that the database will use to initialize the database (see the \"Environment Variables\" section in the MySQL Docker Hub listing ). docker run -d \\ --network todo-app --network-alias mysql \\ -v todo-mysql-data:/var/lib/mysql \\ -e MYSQL_ROOT_PASSWORD = secret \\ -e MYSQL_DATABASE = todos \\ mysql:5.7 If you are using PowerShell then use this command. docker run -d ` - -network todo-app - -network-alias mysql ` -v todo-mysql-data : / var / lib / mysql ` -e MYSQL_ROOT_PASSWORD = secret ` -e MYSQL_DATABASE = todos ` mysql : 5 . 7 You'll also see we specified the --network-alias flag. We'll come back to that in just a moment. Pro-tip You'll notice we're using a volume named todo-mysql-data here and mounting it at /var/lib/mysql , which is where MySQL stores its data. However, we never ran a docker volume create command. Docker recognizes we want to use a named volume and creates one automatically for us. Troubleshooting If you see a docker: no matching manifest error, it's because you're trying to run the container in a different architecture than amd64, which is the only supported architecture for the mysql image at the moment. To solve this add the flag --platform linux/amd64 in the previous command. So your new command should look like this: docker run -d \\ --network todo-app --network-alias mysql --platform linux/amd64 \\ -v todo-mysql-data:/var/lib/mysql \\ -e MYSQL_ROOT_PASSWORD = secret \\ -e MYSQL_DATABASE = todos \\ mysql:5.7 To confirm we have the database up and running, connect to the database and verify it connects. docker exec -it <mysql-container-id> mysql -p When the password prompt comes up, type in secret . In the MySQL shell, list the databases and verify you see the todos database. mysql> SHOW DATABASES; You should see output that looks like this: +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | | todos | +--------------------+ 5 rows in set (0.00 sec) Hooray! We have our todos database and it's ready for us to use! To exit the sql terminal type exit in the terminal.","title":"Starting MySQL"},{"location":"pages/db/#connecting-to-mysql","text":"Now that we know MySQL is up and running, let's use it! But, the question is... how? If we run another container on the same network, how do we find the container (remember each container has its own IP address)? To figure it out, we're going to make use of the nicolaka/netshoot container, which ships with a lot of tools that are useful for troubleshooting or debugging networking issues. Start a new container using the nicolaka/netshoot image. Make sure to connect it to the same network. docker run -it --network todo-app nicolaka/netshoot Inside the container, we're going to use the dig command, which is a useful DNS tool. We're going to look up the IP address for the hostname mysql . dig mysql And you'll get an output like this... ; <<>> DiG 9.14.1 <<>> mysql ;; global options: +cmd ;; Got answer: ;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 32162 ;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0 ;; QUESTION SECTION: ;mysql. IN A ;; ANSWER SECTION: mysql. 600 IN A 172.23.0.2 ;; Query time: 0 msec ;; SERVER: 127.0.0.11#53(127.0.0.11) ;; WHEN: Tue Oct 01 23:47:24 UTC 2019 ;; MSG SIZE rcvd: 44 In the \"ANSWER SECTION\", you will see an A record for mysql that resolves to 172.23.0.2 (your IP address will most likely have a different value). While mysql isn't normally a valid hostname, Docker was able to resolve it to the IP address of the container that had that network alias (remember the --network-alias flag we used earlier?). What this means is... our app only simply needs to connect to a host named mysql and it'll talk to the database! It doesn't get much simpler than that!","title":"Connecting to MySQL"},{"location":"pages/db/#running-our-app-with-mysql","text":"The todo app supports the setting of a few environment variables to specify MySQL connection settings. They are: MYSQL_HOST - the hostname for the running MySQL server MYSQL_USER - the username to use for the connection MYSQL_PASSWORD - the password to use for the connection MYSQL_DB - the database to use once connected Warning While using env vars to set connection settings is generally ok for development, it is HIGHLY DISCOURAGED when running applications in production. Diogo Monica, the former lead of security at Docker, wrote a fantastic blog post explaining why. A more secure mechanism is to use the secret support provided by your container orchestration framework. In most cases, these secrets are mounted as files in the running container. You'll see many apps (including the MySQL image and the todo app) also support env vars with a _FILE suffix to point to a file containing the variable. As an example, setting the MYSQL_PASSWORD_FILE var will cause the app to use the contents of the referenced file as the connection password. Docker doesn't do anything to support these env vars. Your app will need to know to look for the variable and get the file contents. With all of that explained, let's start our dev-ready container! We'll specify each of the environment variables above, as well as connect the container to our app network. docker run -dp 3000 :3000 \\ -w /app -v \" $( pwd ) :/app\" \\ --network todo-app \\ -e MYSQL_HOST = mysql \\ -e MYSQL_USER = root \\ -e MYSQL_PASSWORD = secret \\ -e MYSQL_DB = todos \\ node:12-alpine \\ sh -c \"yarn install && yarn run dev\" If you updated your docker file in the Bind Mount section of the tutorial use the updated command: docker run -dp 3000 :3000 \\ -w /app -v \" $( pwd ) :/app\" \\ --network todo-app \\ -e MYSQL_HOST = mysql \\ -e MYSQL_USER = root \\ -e MYSQL_PASSWORD = secret \\ -e MYSQL_DB = todos \\ node:12-alpine \\ sh -c \"apk --no-cache --virtual build-dependencies add python2 make g++ && yarn install && yarn run dev\" If you are using PowerShell then use this command. docker run -dp 3000 : 3000 ` -w / app -v \" $( pwd ) :/app\" ` - -network todo-app ` -e MYSQL_HOST = mysql ` -e MYSQL_USER = root ` -e MYSQL_PASSWORD = secret ` -e MYSQL_DB = todos ` node : 12-alpine ` sh -c \"yarn install && yarn run dev\" If we look at the logs for the container ( docker logs <container-id> ), we should see a message indicating it's using the mysql database. # Previous log messages omitted $ nodemon src/index.js [nodemon] 1.19.2 [nodemon] to restart at any time, enter `rs` [nodemon] watching dir(s): *.* [nodemon] starting `node src/index.js` Connected to mysql db at host mysql Listening on port 3000 Open the app in your browser and add a few items to your todo list. Connect to the mysql database and prove that the items are being written to the database. Remember, the password is secret . docker exec -it <mysql-container-id> mysql -p todos And in the mysql shell, run the following: mysql> select * from todo_items; +--------------------------------------+--------------------+-----------+ | id | name | completed | +--------------------------------------+--------------------+-----------+ | c906ff08-60e6-44e6-8f49-ed56a0853e85 | Do amazing things! | 0 | | 2912a79e-8486-4bc3-a4c5-460793a575ab | Be awesome! | 0 | +--------------------------------------+--------------------+-----------+ Obviously, your table will look different because it has your items. But, you should see them stored there! If you take a quick look at the Docker Dashboard, you'll see that we have two app containers running. But, there's no real indication that they are grouped together in a single app. We'll see how to make that better shortly!","title":"Running our App with MySQL"},{"location":"pages/db/#recap","text":"At this point, we have an application that now stores its data in an external database running in a separate container. We learned a little bit about container networking and saw how service discovery can be performed using DNS.","title":"Recap"},{"location":"pages/db/#docker-volumes","text":"In containerized applications, the data by default is being wiped clean every single time we launch the container. Why is this? Let's dive into how the container is working.","title":"Docker volumes"},{"location":"pages/db/#the-containers-filesystem","text":"When a container runs, it uses the various layers from an image for its filesystem. Each container also gets its own \"scratch space\" to create/update/remove files. Any changes won't be seen in another container, even if they are using the same image.","title":"The Container's Filesystem"},{"location":"pages/db/#container-volumes","text":"With the previous experiment, we saw that each container starts from the image definition each time it starts. While containers can create, update, and delete files, those changes are lost when the container is removed and all changes are isolated to that container. With volumes, we can change all of this. Volumes provide the ability to connect specific filesystem paths of the container back to the host machine. If a directory in the container is mounted, changes in that directory are also seen on the host machine. If we mount that same directory across container restarts, we'd see the same files. So far, we talked about and used a named volume to persist the data in our database. Named volumes are great if we simply want to store data, as we don't have to worry about where the data is stored. With bind mounts , we control the exact mountpoint on the host. We can use this to persist data, but is often used to provide additional data into containers. When working on an application, we can use a bind mount to mount our source code into the container to let it see code changes, respond, and let us see the changes right away. For Node-based applications, nodemon is a great tool to watch for file changes and then restart the application. There are equivalent tools in most other languages and frameworks.","title":"Container Volumes"},{"location":"pages/license/","text":"Apache License Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION Definitions. \"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. \"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. \"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License. \"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. \"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. \"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). \"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. \"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\" \"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and \u00a9 You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS APPENDIX: How to apply the Apache License to your work. To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets \"[]\" replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \"printed page\" as the copyright notice for easier identification within third-party archives. Copyright [2022] [Alexander Martinez Fajardo] Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"License"},{"location":"pages/milestones/","text":"Milestons","title":"Goals and milestones"},{"location":"pages/reqs/","text":"Features \u00b6 API Server Backend \u00b6 User Registration Authentication using JWT and OAuth \"password flow\" using PyJWT JSON-Web-Token based authentication Writing & modifying user data on the database. Backend API endpoints for general and to support CRUD operations Manage patients and users. Calculate pellets dose based on scientific data and algorithm (business logic) Security Resilient database using dockerrized MySQL database ReactJS Frontend \u00b6 The single-page-application frontend will be developed in Javascript using React JS. The frontend will have the following components - Routing using React Router Login component Register component State management using Recoil. (Recoil is kinda cool. Check it out.) Admin Dashboard Higher Order Components (privateroute) Utility functions and higher-order components for handling authentication The login, register & endpoint handler component will call the API we built earlier. The login & register component will POST request the API which will return the JSON Web token to make authenticated calls to the other endpoints. The app state is just an authentication flag & user data for now. The example handler will check the auth flag before calling our API. The frontend code will also be deployed on a docker container. We\u2019ll use the basic Nginx image. The react code will sit behind an nginx server. The nginx server will also handle the API requests at /api and redirect them to the API server. Persistent Storage \u00b6 The user and patient data will be stored on a Postgres database. For now, we will just store the user\u2019s and doctor's email and password. The patient table will have more data stored. The easiest way to get postgres on production environment use a Docker image. Non-functional requirements \u00b6 Deploy using Docker Compose Docker-Compose is an awesome tool that can handle multiple container deployments on the same host. We are creating 3 different containers for the 3 services (api, web, db) which will run on the same host machine. All we need is to create the docker-compose.yaml file. Use FastAPI as backend api technology. Use ReactJS as frontend technology. MySQL as relational database management system. SQLAlchemy as Object Relational Mapper (ORM) Alembic for database migrations. Deployment on Deta for FastAPI backend API and Netlify for frontend UI. Dependencies \u00b6 React v18.1.0 Create React App v5.0.1 Node v18.2.0 npm v8.9.0 npx v8.9.0 FastAPI v0.78.0 Python v3.10 Development Philosophy \u00b6 We'll start by scaffolding a new React app with the Create React App CLI before building the backend RESTful API with FastAPI. Finally, we'll develop the backend routes along with the frontend, React components.","title":"Our application"},{"location":"pages/reqs/#features","text":"","title":"Features"},{"location":"pages/reqs/#api-server-backend","text":"User Registration Authentication using JWT and OAuth \"password flow\" using PyJWT JSON-Web-Token based authentication Writing & modifying user data on the database. Backend API endpoints for general and to support CRUD operations Manage patients and users. Calculate pellets dose based on scientific data and algorithm (business logic) Security Resilient database using dockerrized MySQL database","title":"API Server Backend"},{"location":"pages/reqs/#reactjs-frontend","text":"The single-page-application frontend will be developed in Javascript using React JS. The frontend will have the following components - Routing using React Router Login component Register component State management using Recoil. (Recoil is kinda cool. Check it out.) Admin Dashboard Higher Order Components (privateroute) Utility functions and higher-order components for handling authentication The login, register & endpoint handler component will call the API we built earlier. The login & register component will POST request the API which will return the JSON Web token to make authenticated calls to the other endpoints. The app state is just an authentication flag & user data for now. The example handler will check the auth flag before calling our API. The frontend code will also be deployed on a docker container. We\u2019ll use the basic Nginx image. The react code will sit behind an nginx server. The nginx server will also handle the API requests at /api and redirect them to the API server.","title":"ReactJS Frontend"},{"location":"pages/reqs/#persistent-storage","text":"The user and patient data will be stored on a Postgres database. For now, we will just store the user\u2019s and doctor's email and password. The patient table will have more data stored. The easiest way to get postgres on production environment use a Docker image.","title":"Persistent Storage"},{"location":"pages/reqs/#non-functional-requirements","text":"Deploy using Docker Compose Docker-Compose is an awesome tool that can handle multiple container deployments on the same host. We are creating 3 different containers for the 3 services (api, web, db) which will run on the same host machine. All we need is to create the docker-compose.yaml file. Use FastAPI as backend api technology. Use ReactJS as frontend technology. MySQL as relational database management system. SQLAlchemy as Object Relational Mapper (ORM) Alembic for database migrations. Deployment on Deta for FastAPI backend API and Netlify for frontend UI.","title":"Non-functional requirements"},{"location":"pages/reqs/#dependencies","text":"React v18.1.0 Create React App v5.0.1 Node v18.2.0 npm v8.9.0 npx v8.9.0 FastAPI v0.78.0 Python v3.10","title":"Dependencies"},{"location":"pages/reqs/#development-philosophy","text":"We'll start by scaffolding a new React app with the Create React App CLI before building the backend RESTful API with FastAPI. Finally, we'll develop the backend routes along with the frontend, React components.","title":"Development Philosophy"},{"location":"pages/ui/","text":"","title":"User interface Prototypes"}]}